{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction from pack P180_2,3,4 and P190_2,3,4"
      ],
      "metadata": {
        "id": "QFiBugwJRgWB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLMiuVHLWivy",
        "outputId": "1d8ffc5e-e249-4001-9ce5-b52bc83fc71c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm\n",
        "from tables.table import Column\n",
        "import seaborn as sns\n",
        "import scipy.stats\n",
        "import plotly.express as px\n",
        "from IPython.display import clear_output\n",
        "from scipy.interpolate import interp1d\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "j8s6xyB-bO8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set working directory containg the Data\n",
        "os.chdir('/content/drive/Shareddrives/R&D/Projects/DataforManuscript/')"
      ],
      "metadata": {
        "id": "NUwqmpLFSuQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install plotly"
      ],
      "metadata": {
        "id": "rEJW4IyXcqSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82b1d10-6b21-4fe8-e325-f32ed946d012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction function"
      ],
      "metadata": {
        "id": "s6dl808qXxYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Nyquist_feature_extract(Zreal,Zimg,num_interp,plotflag,Zreal_exclude=[],num_nearest_smooth=10,portion_from_end=20,turn_correction=0,defined_index_start=3,defined_index_end=-5,defined_turn=0):\n",
        "#define the fucntion to interpolate nyquist plot, find features, plot and return the feature valuesinput filename, number of data points for interpolation. Input Zreal, Zimg are numpy arrays\n",
        "#to return features: ymax=maximum of Zimg, xofymax=zreal value of maximum of Zimg,intercept=intercept with x-axis,diameter=diameter of semicircle, tailhead=start of linear tail,\n",
        "#slope=slope of linear tail,shoulder=the beginning of second semicircle or zero\n",
        "#shape=representation of shape (center-0.5max)/(center-0.75max),shoulder=min(2nd dervative before the tip of the large circle)\n",
        "\n",
        "#Zreal and Zimg are input of real and imaginary inputs in dataframe format\n",
        "#num_interp is the total number of points to interpolate the raw data onto\n",
        "#plotflag is the flag to plot interactive plot using plotly\n",
        "#Zreal_exclude is the Zreal value of datapoint to exlucde, e.g. [0.0005,0.0006]\n",
        "#num_nearest_smooth is the number of neignboring data point used to smooth the curve for finding the start of tail\n",
        "#portion_from_end is used to discard the detected start of tail if it is too close to the end of data\n",
        "#turn_correction is the number of interpolated data points to correct from detected turn\n",
        "#defined_index_start and defined_index_end are used for detectbing shoulder in the case of two semicircules. They can be set to exclude the nosiy low Zimg region and the flat region\n",
        "#defined_turn is the option to set Zreal value of turn\n",
        "\n",
        "\n",
        "\n",
        "  #data = pd.read_csv(filename, delimiter = ',', header = 0, encoding='latin1')\n",
        "  toprint=\" \" #filename.split(\"/\")\n",
        "\n",
        "  #convert from dataframe to array\n",
        "  x=Zreal\n",
        "  y=Zimg\n",
        "  x=x[y>-0.001]\n",
        "  y=y[y>-0.001]\n",
        "\n",
        "  #delete datapoints from Zreal_exclude\n",
        "  for exclude in Zreal_exclude:\n",
        "    x = np.delete( x,np.abs(x - exclude).argmin())\n",
        "    y = np.delete( y,np.abs(x - exclude).argmin())\n",
        "\n",
        "\n",
        "  #interpolate Zreal and Zimg above-x-axis part\n",
        "  f = interp1d(x, y)\n",
        "  #f2 = interp1d(x, y, kind='cubic')\n",
        "  xnew = np.linspace(np.min(x), np.max(x), num=num_interp, endpoint=True)\n",
        "  ynew=f(xnew)\n",
        "\n",
        "  ################################find features#############################################################\n",
        "  #initialize outputs in case there are errors\n",
        "  xofymax=0\n",
        "  ymax=0\n",
        "  tailhead=0\n",
        "  intercept=0\n",
        "  slope=0\n",
        "  diameter=0\n",
        "  shape=0\n",
        "  shoulder=0\n",
        "\n",
        "  x_tail=[1] * 9\n",
        "  y_tail=[1] * 9\n",
        "  x_fit=[1]*9\n",
        "  coef = np.polyfit(x_tail,y_tail,1)\n",
        "  poly1d_fn = np.poly1d(coef)\n",
        "\n",
        "  center_HM=0\n",
        "  leftcross_HM=0\n",
        "  rightcross_HM=0\n",
        "  center_QM=0\n",
        "  leftcross_QM=0\n",
        "  rightcross_QM=0\n",
        "\n",
        "\n",
        "  #find intercept, rough maximum and separate data to before and after max\n",
        "\n",
        "  positive=np.where(ynew>0) #find the positive part\n",
        "\n",
        "  #find the top of the semicircle\n",
        "\n",
        "  def running_mean_cumsum(x, N):\n",
        "    #average mean filter with sum of nearby points\n",
        "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
        "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
        "\n",
        "  #apply average filter on y and propogate x data points to find roughly where the turn is\n",
        "  y_convolved = running_mean_cumsum(y[defined_index_start:defined_index_end], num_nearest_smooth)\n",
        "  x_convolved = np.linspace(np.min(x[defined_index_start:defined_index_end]), np.max(x[defined_index_start:defined_index_end]), num=len(y_convolved), endpoint=True)\n",
        "\n",
        "  turn_convolved=np.where(np.gradient(np.gradient(y_convolved, 0.0001), 0.0001)==max(np.gradient(np.gradient(y_convolved, 0.0001), 0.0001)))\n",
        "\n",
        "  #find the tip of semicircle\n",
        "  if defined_turn > 0:\n",
        "    turn_initial=np.abs(xnew - defined_turn).argmin()\n",
        "    tip=np.where(ynew==np.max(ynew[0:turn_initial-turn_correction]))\n",
        "    start=turn_initial\n",
        "  elif np.abs(np.where(ynew==np.max(ynew))[0][0]-num_interp) < round(num_interp/portion_from_end):\n",
        "    # if the tailend is higher than semicicle\n",
        "    turn_initial=np.abs(xnew - x_convolved[turn_convolved]).argmin()\n",
        "    tip=np.where(ynew==np.max(ynew[0:turn_initial+turn_correction]))\n",
        "  else:\n",
        "    # if the tailend is lower than semicircle\n",
        "    tip=np.where(ynew==np.max(ynew))\n",
        "\n",
        "  #split data to two parts, one beofre the top of semicirlce, the other after\n",
        "  beforetip=ynew[0:tip[0][0]]\n",
        "  aftertip=ynew[tip[0][0]:-1]\n",
        "  if defined_turn==0:\n",
        "    turn=np.where(aftertip==np.min(aftertip)) #find the start of tail\n",
        "    start=turn[0][0]\n",
        "\n",
        "  try:\n",
        "    # find half max and 0.75 max lines\n",
        "    #find the region before the tail and after the tip of semicircle\n",
        "    rightcircle=aftertip[0:start]\n",
        "    #find values at half maximum of top of the circle\n",
        "    rightcross_HM=xnew.flat[np.abs(rightcircle - ynew[tip[0][0]]/2).argmin()+tip[0][0]]\n",
        "    #find values at 0.75 maximum of top of the circle\n",
        "    rightcross_QM=xnew.flat[np.abs(rightcircle - 0.75*ynew[tip[0][0]]).argmin()+tip[0][0]]\n",
        "\n",
        "\n",
        "    #find the leftcross and center for halfmax or 0.75 max of the semicircle\n",
        "    leftcross_HM=xnew.flat[np.abs(beforetip - np.max(beforetip)/2).argmin()]\n",
        "    center_HM=(leftcross_HM+rightcross_HM)/2\n",
        "    leftcross_QM=xnew.flat[np.abs(beforetip - 0.75*np.max(beforetip)).argmin()]\n",
        "    center_QM=(leftcross_QM+rightcross_QM)/2\n",
        "\n",
        "    try:\n",
        "      #find the shoulder, beginning of second semicircle by minimum 1st deriative\n",
        "      beforetip_y=ynew[(ynew>0) & (xnew<leftcross_QM)] #[positive[0][0]:tip[0][0]-50]\n",
        "      beforetip_x=xnew[(ynew>0) & (xnew<leftcross_QM)] #[positive[0][0]:tip[0][0]-50]\n",
        "      beforetip_y_convolved = running_mean_cumsum(beforetip_y, 3)\n",
        "      beforetip_x_convolved = np.linspace(np.min(beforetip_x), np.max(beforetip_x), num=len(beforetip_y_convolved), endpoint=True)\n",
        "      shoulder_convolved=np.where(np.gradient(beforetip_y_convolved, 0.0001)==min(np.gradient(beforetip_y_convolved, 0.0001)))\n",
        "      shoulder=beforetip_x_convolved[shoulder_convolved[0][0]]\n",
        "      if abs(shoulder-leftcross_QM)<0.0006:\n",
        "        shoulder=0\n",
        "    except:\n",
        "      print(\"Error in Nyquist_feature_extract(): shoulder is wrong\")\n",
        "\n",
        "\n",
        "    try:\n",
        "      #extract slope for the tail with linear fit\n",
        "      if defined_turn>0:\n",
        "        x_tail=xnew[start:-1]\n",
        "        y_tail=ynew[start:-1]\n",
        "      else:\n",
        "        x_tail=xnew[len(xnew)-round(0.7*(len(xnew)-start-tip[0][0])):-1]\n",
        "        y_tail=ynew[len(xnew)-round(0.7*(len(xnew)-start-tip[0][0])):-1]\n",
        "\n",
        "      x_fit=np.linspace(0,0.2,100)\n",
        "      coef = np.polyfit(x_tail,y_tail,1)\n",
        "      poly1d_fn = np.poly1d(coef)\n",
        "\n",
        "\n",
        "      #assign values to turn\n",
        "      intercept=xnew[positive[0][0]]\n",
        "      xofymax=xnew[tip[0][0]]\n",
        "      ymax=ynew[tip[0][0]]\n",
        "      if defined_turn==0:\n",
        "        tailhead=xnew[start+tip[0][0]]\n",
        "      else:\n",
        "        tailhead=xnew[start]\n",
        "      slope=coef[0]\n",
        "      diameter=2*(center_HM-xnew[positive[0][0]])\n",
        "      shape=(center_HM-leftcross_HM)/(center_QM-leftcross_QM)#(leftcross_QM-intercept)/(leftcross_HM-intercept)\n",
        "    except:\n",
        "      print(\"Error in Nyquist_feature_extract(): linear region empty\")\n",
        "  except:\n",
        "    print(\"Error in Nyquist_feature_extract(): start of tail is wrong\")\n",
        "\n",
        "\n",
        "  ################################################plot features#########################################################################\n",
        "  if plotflag==1:\n",
        "    #plot raw and interpoplated data\n",
        "    fig = px.line(x=xnew, y=ynew,color_discrete_sequence=[\"black\"],title=toprint[-1], width=800,height=400)\n",
        "    fig.add_scatter( x=Zreal, y=Zimg,mode=\"markers\",name=\"raw data\")\n",
        "\n",
        "    #plot fitted line for tail\n",
        "    fig.add_scatter( x=x_tail, y=y_tail,mode=\"markers\",name=\"diffusion line\")\n",
        "    fig.add_scatter( x=x_fit, y=poly1d_fn(x_fit),mode=\"lines\",name=\"diffusion line fitting\")\n",
        "\n",
        "    #plot vertical lines for intercept, maximum, and start of tail\n",
        "    fig.add_vline(x = xofymax, line_width=2, line_color=\"green\", \\\n",
        "            label=dict(\n",
        "            text=\"maximum\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"green\"))) #start of tail\n",
        "    fig.add_vline(x = tailhead, line_width=2, line_color=\"black\", \\\n",
        "            label=dict(\n",
        "            text=\"start of tail\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"black\"))) #start of tail\n",
        "    fig.add_vline(x = intercept, line_width=2, line_color=\"red\", \\\n",
        "            label=dict(\n",
        "            text=\"intercept\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"red\"))) #x-axis intercept\n",
        "\n",
        "    #plot lines to find center by half max\n",
        "    fig.add_vline(x = center_HM, line_width=2, line_color=\"orange\", \\\n",
        "            label=dict(\n",
        "            text=\"\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"orange\"))) #center of semicircle\n",
        "    fig.add_vline(x = leftcross_HM, line_width=2, line_color=\"orange\", \\\n",
        "            label=dict(\n",
        "            text=\"\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"orange\"))) #half max\n",
        "    fig.add_vline(x = rightcross_HM, line_width=2, line_color=\"orange\", \\\n",
        "            label=dict(\n",
        "            text=\"\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"orange\"))) #half max\n",
        "    fig.add_hline(y = ynew[tip[0][0]]/2, line_width=2, line_color=\"orange\", \\\n",
        "            label=dict(\n",
        "            text=\"half max\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"orange\"))) #half max\n",
        "\n",
        "    #plot lines to find center by quarter max\n",
        "    fig.add_vline(x = center_QM, line_width=2, line_color=\"purple\", \\\n",
        "            label=dict(\n",
        "            text=\"\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"purple\"))) #center of semicircle\n",
        "    fig.add_vline(x = leftcross_QM, line_width=2, line_color=\"purple\", \\\n",
        "            label=dict(\n",
        "            text=\"\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"purple\"))) #three quarters max\n",
        "    fig.add_vline(x = rightcross_QM, line_width=2, line_color=\"purple\", \\\n",
        "            label=dict(\n",
        "            text=\"\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"purple\"))) #three quarters max\n",
        "    fig.add_hline(y = 0.75*ynew[tip[0][0]], line_width=2, line_color=\"purple\", \\\n",
        "            label=dict(\n",
        "            text=\"0.75 max\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"purple\"))) #half max\n",
        "\n",
        "    #plot line at the beginning of the second circle\n",
        "    fig.add_vline(x = shoulder, line_width=2, line_color=\"blue\", \\\n",
        "            label=dict(\n",
        "            text=\"shoulder\",\n",
        "            textposition=\"end\",\n",
        "            font=dict(size=12, color=\"blue\"))) #center of semicircle\n",
        "\n",
        "\n",
        "    fig.update_yaxes(range=[0, max(y)])\n",
        "    fig.update_xaxes(range=[0.9*min(x), max(x)])\n",
        "    fig.show()\n",
        "  return xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax\n",
        "\n",
        "#xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0,defined_turn=0.045) #filename, number of datapoints to interpolate, flag 1 to plot"
      ],
      "metadata": {
        "id": "U2z6-CASwjXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction features from packs"
      ],
      "metadata": {
        "id": "GzCHUB65S8Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#extract features in pack P180-02,3,4\n",
        "my_dict = {}\n",
        "for i in [2,3,4]:\n",
        "  #get filenames of EIS from all cells\n",
        "  directory = r'Data/P180/P180_0'+str(i)+'/'\n",
        "  all_files = glob.glob(os.path.join(directory,  r'EIS_*/2_EIS_*_P180_0'+str(i)+'_*.csv'))\n",
        "  n=len(all_files)\n",
        "\n",
        "  #initialize dataframes for features for each pack\n",
        "  #features: ymax=maximum of Zimg, intercept=intercept with x-axis,diameter=diameter of semicircle, tailhead=start of linear tail, slope=slope of linear tail, shape=representation of shape (center-0.5max)/(center-0.75max)\n",
        "  for x in [r\"pack_xofymax_P180_0\"+str(i),r\"pack_intercept_P180_0\"+str(i),r\"pack_diameter_P180_0\"+str(i),r\"pack_tailhead_P180_0\"+str(i),r\"pack_slope_P180_0\"+str(i),r\"pack_shape_P180_0\"+str(i),\\\n",
        "            r\"pack_shoulder_P180_0\"+str(i),r\"pack_ymax_P180_0\"+str(i)]:\n",
        "    my_dict[x] =pd.DataFrame(columns=[\"scan\"+str(j) for j in [2,4,6,8]],index=[\"P180_0\"+str(i)+\"_\"+str(j) for j in range(1,6)])\n",
        "\n",
        "\n",
        "  for filename in all_files:\n",
        "    data = pd.read_csv(filename, delimiter = ',', header = 0, encoding='latin1')\n",
        "\n",
        "    pre=filename.split(\"/\")\n",
        "    key=pre[-1].split(\"_\")\n",
        "    cell=key[5].split(\" \")\n",
        "\n",
        "    x=data[\"Z' (Ohms)\"].to_numpy()\n",
        "    y=data['-Z\" (Ohms)'].to_numpy()\n",
        "\n",
        "    print([\"scan\"+key[2] + \"_P180_\" + key[4]+\"_\"+cell[0]])\n",
        "\n",
        "    xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0)\n",
        "\n",
        "    my_dict[r\"pack_xofymax_P180_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P180_0\"+str(i)+\"_\"+cell[0]]=xofymax #x of maximum of Zimg\n",
        "    my_dict[r\"pack_intercept_P180_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P180_0\"+str(i)+\"_\"+cell[0]]=intercept #intercept\n",
        "    my_dict[r\"pack_tailhead_P180_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P180_0\"+str(i)+\"_\"+cell[0]]=tailhead #start of tail\n",
        "    my_dict[r\"pack_slope_P180_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P180_0\"+str(i)+\"_\"+cell[0]]=slope #slope of tail\n",
        "    my_dict[r\"pack_diameter_P180_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P180_0\"+str(i)+\"_\"+cell[0]]=diameter #diameter of semicircle obtained from half max\n",
        "    my_dict[r\"pack_shape_P180_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P180_0\"+str(i)+\"_\"+cell[0]]=shape #shape=representation of shape (0.75max-Rs)/(0.5max-Rs)\n",
        "    my_dict[r\"pack_shoulder_P180_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P180_0\"+str(i)+\"_\"+cell[0]]=shoulder #\n",
        "    my_dict[r\"pack_ymax_P180_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P180_0\"+str(i)+\"_\"+cell[0]]=ymax #maximum of Zimg\n",
        "\n",
        "  #stack features of one pack together to save\n",
        "  Feature=pd.concat([my_dict[\"pack_\"+Feature_name+\"_P180_0\"+str(i)] for Feature_name in [\"xofymax\",\"intercept\",\"diameter\",\"tailhead\",\"slope\",\"shape\",\"shoulder\",\"ymax\"]])\n",
        "  currentDateTime = datetime.now().strftime(\"%m-%d-%Y %H-%M-%S %p\")\n",
        "  Feature.to_csv(\"Generated Features/P180_0\"+str(i)+f\"_features {currentDateTime}.csv\", index = True)"
      ],
      "metadata": {
        "id": "xwMFCKbW_n6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#extract features in pack P190_02\n",
        "my_dict = {}\n",
        "for i in [2]:\n",
        "  #get filenames of EIS from all cells\n",
        "  directory = r'Data/P190/P190_0'+str(i)+'/'\n",
        "  all_files = glob.glob(os.path.join(directory,  r'EIS_*/2_EIS_*_P190_0'+str(i)+'_*'))\n",
        "  n=len(all_files)\n",
        "\n",
        "  #initialize dataframes for features for each pack\n",
        "  for x in [r\"pack_xofymax_P190_0\"+str(i),r\"pack_intercept_P190_0\"+str(i),r\"pack_diameter_P190_0\"+str(i),r\"pack_tailhead_P190_0\"+str(i),r\"pack_slope_P190_0\"+str(i),r\"pack_shape_P190_0\"+str(i),r\"pack_shoulder_P190_0\"+str(i),r\"pack_ymax_P190_0\"+str(i)]:\n",
        "    my_dict[x] =pd.DataFrame(columns=[\"scan\"+str(j) for j in [2,4,6,8]],index=[\"P190_0\"+str(i)+\"_\"+str(j) for j in range(1,6)])\n",
        "\n",
        "\n",
        "  for filename in all_files:\n",
        "    data = pd.read_csv(filename, delimiter = ',', header = 0, encoding='latin1')\n",
        "\n",
        "    pre=filename.split(\"/\")\n",
        "    key=pre[-1].split(\"_\")\n",
        "    cell=key[5].split(\" \")\n",
        "\n",
        "    x=data[\"Z' (Ohms)\"].to_numpy()\n",
        "    y=data['-Z\" (Ohms)'].to_numpy()\n",
        "\n",
        "    #print([\"scan\"+key[2] + \"_P190_\" + key[4]+\"_\"+cell[0]])\n",
        "    xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0)\n",
        "\n",
        "    my_dict[r\"pack_xofymax_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=xofymax #x of maximum of Zimg\n",
        "    my_dict[r\"pack_intercept_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=intercept #intercept\n",
        "    my_dict[r\"pack_tailhead_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=tailhead #start of tail\n",
        "    my_dict[r\"pack_slope_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=slope #slope of tail\n",
        "    my_dict[r\"pack_diameter_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=diameter #diameter of semicircle obtained from half max\n",
        "    my_dict[r\"pack_shape_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=shape #shape=representation of shape (0.75max-Rs)/(0.5max-Rs)\n",
        "    my_dict[r\"pack_shoulder_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=shoulder #\n",
        "    my_dict[r\"pack_ymax_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=ymax #maximum of Zimg\n",
        "\n",
        "  #stack features of one pack together to save\n",
        "  Feature=pd.concat([my_dict[\"pack_\"+Feature_name+\"_P190_0\"+str(i)] for Feature_name in [\"xofymax\",\"intercept\",\"diameter\",\"tailhead\",\"slope\",\"shape\",\"shoulder\",\"ymax\"]])\n",
        "  currentDateTime = datetime.now().strftime(\"%m-%d-%Y %H-%M-%S %p\")\n",
        "  Feature.to_csv(\"Generated Features/P190_0\"+str(i)+f\"_features {currentDateTime}.csv\", index = True)"
      ],
      "metadata": {
        "id": "a5T9HKUuf9za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#extract features in pack P190-03\n",
        "my_dict = {}\n",
        "for i in [3]:\n",
        "  #get filenames of EIS from all cells\n",
        "  directory = r'Data/P190/P190_0'+str(i)+'/'\n",
        "  all_files = glob.glob(os.path.join(directory,  r'EIS_*/2_EIS_*_P190_0'+str(i)+'_*'))\n",
        "  n=len(all_files)\n",
        "\n",
        "  #initialize dataframes for features for each pack\n",
        "  for x in [r\"pack_xofymax_P190_0\"+str(i),r\"pack_intercept_P190_0\"+str(i),r\"pack_diameter_P190_0\"+str(i),r\"pack_tailhead_P190_0\"+str(i),\\\n",
        "            r\"pack_slope_P190_0\"+str(i),r\"pack_shape_P190_0\"+str(i),r\"pack_shoulder_P190_0\"+str(i),r\"pack_ymax_P190_0\"+str(i)]:\n",
        "    my_dict[x] =pd.DataFrame(columns=[\"scan\"+str(j) for j in [2,4,6,8]],index=[\"P190_0\"+str(i)+\"_\"+str(j) for j in range(1,6)])\n",
        "\n",
        "\n",
        "  for filename in all_files:\n",
        "    data = pd.read_csv(filename, delimiter = ',', header = 0, encoding='latin1')\n",
        "\n",
        "    pre=filename.split(\"/\")\n",
        "    key=pre[-1].split(\"_\")\n",
        "    cell=key[5].split(\" \")\n",
        "\n",
        "\n",
        "    x=data[\"Z' (Ohms)\"].to_numpy()\n",
        "    y=data['-Z\" (Ohms)'].to_numpy()\n",
        "\n",
        "    print([\"scan\"+key[2] + \"_P190_\" + key[4]+\"_\"+cell[0]])\n",
        "\n",
        "    if [int(cell[0]),int(key[2])]==[4,2]:\n",
        "\n",
        "      xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0,Zreal_exclude=[0.05301404,0.05261355])\n",
        "    elif [int(cell[0]),int(key[2])]==[4,8]:\n",
        "\n",
        "      xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0,defined_turn=0.0327)\n",
        "\n",
        "    else:\n",
        "      xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0)\n",
        "\n",
        "\n",
        "    my_dict[r\"pack_xofymax_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=xofymax #x of maximum of Zimg\n",
        "    my_dict[r\"pack_intercept_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=intercept #intercept\n",
        "    my_dict[r\"pack_tailhead_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=tailhead #start of tail\n",
        "    my_dict[r\"pack_slope_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=slope #slope of tail\n",
        "    my_dict[r\"pack_diameter_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=diameter #diameter of semicircle obtained from half max\n",
        "    my_dict[r\"pack_shape_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=shape #shape=representation of shape (0.75max-Rs)/(0.5max-Rs)\n",
        "    my_dict[r\"pack_shoulder_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=shoulder #\n",
        "    my_dict[r\"pack_ymax_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=ymax #maximum of Zimg\n",
        "\n",
        "  #stack features of one pack together to save\n",
        "  Feature=pd.concat([my_dict[\"pack_\"+Feature_name+\"_P190_0\"+str(i)] for Feature_name in [\"xofymax\",\"intercept\",\"diameter\",\"tailhead\",\"slope\",\"shape\",\"shoulder\",\"ymax\"]])\n",
        "  currentDateTime = datetime.now().strftime(\"%m-%d-%Y %H-%M-%S %p\")\n",
        "  Feature.to_csv(\"Generated Features/P190_0\"+str(i)+f\"_features {currentDateTime}.csv\", index = True)"
      ],
      "metadata": {
        "id": "qS_zPBioqO7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca94d1bd-17c3-403d-ae63-a932e056f466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan08_P190_03_5']\n",
            "['scan02_P190_03_1']\n",
            "['scan02_P190_03_2']\n",
            "['scan02_P190_03_3']\n",
            "['scan02_P190_03_4']\n",
            "['scan02_P190_03_5']\n",
            "['scan04_P190_03_1']\n",
            "['scan04_P190_03_2']\n",
            "['scan04_P190_03_3']\n",
            "['scan04_P190_03_4']\n",
            "['scan04_P190_03_5']\n",
            "['scan06_P190_03_1']\n",
            "['scan06_P190_03_2']\n",
            "['scan06_P190_03_3']\n",
            "['scan06_P190_03_4']\n",
            "['scan06_P190_03_5']\n",
            "['scan08_P190_03_1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan08_P190_03_2']\n",
            "['scan08_P190_03_3']\n",
            "['scan08_P190_03_4']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n",
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#extract features in pack P190-04\n",
        "my_dict = {}\n",
        "for i in [4]:\n",
        "  #get filenames of EIS from all cells\n",
        "  directory = r'Data/P190/P190_0'+str(i)+'/'\n",
        "  all_files = glob.glob(os.path.join(directory,  r'EIS_*/2_EIS_*_P190_0'+str(i)+'_*'))\n",
        "  n=len(all_files)\n",
        "\n",
        "  #initialize dataframes for features for each pack\n",
        "  #features: ymax=maximum of Zimg, intercept=intercept with x-axis,diameter=diameter of semicircle, tailhead=start of linear tail, slope=slope of linear tail, shape=representation of shape (center-0.5max)/(center-0.75max)\n",
        "  for x in [r\"pack_xofymax_P190_0\"+str(i),r\"pack_intercept_P190_0\"+str(i),r\"pack_diameter_P190_0\"+str(i),r\"pack_tailhead_P190_0\"+str(i),r\"pack_slope_P190_0\"+str(i),r\"pack_shape_P190_0\"+str(i),r\"pack_shoulder_P190_0\"+str(i),r\"pack_ymax_P190_0\"+str(i)]:\n",
        "    my_dict[x] =pd.DataFrame(columns=[\"scan\"+str(j) for j in [2,4,6,8]],index=[\"P190_0\"+str(i)+\"_\"+str(j) for j in range(1,6)])\n",
        "\n",
        "\n",
        "  for filename in all_files:\n",
        "    data = pd.read_csv(filename, delimiter = ',', header = 0, encoding='latin1')\n",
        "\n",
        "    pre=filename.split(\"/\")\n",
        "    key=pre[-1].split(\"_\")\n",
        "    cell=key[5].split(\" \")\n",
        "\n",
        "\n",
        "    x=data[\"Z' (Ohms)\"].to_numpy()\n",
        "    y=data['-Z\" (Ohms)'].to_numpy()\n",
        "\n",
        "    print([\"scan\"+key[2] + \"_P190_\" + key[4]+\"_\"+cell[0]])\n",
        "\n",
        "\n",
        "\n",
        "    if [int(cell[0]),int(key[2])]==[2,4]:\n",
        "\n",
        "      xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=0,0,0,0,0,0,0,0\n",
        "    elif [int(cell[0]),int(key[2])]==[3,8]:\n",
        "      xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0,defined_turn=0.03)\n",
        "    elif [int(cell[0]),int(key[2])] in [[2,8],[4,8],[5,8]]:\n",
        "      xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0,defined_turn=0.034)\n",
        "    elif [int(cell[0]),int(key[2])]==[4,2]:\n",
        "      xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0,defined_turn=0.037)\n",
        "    elif [int(cell[0]),int(key[2])]==[5,2]:\n",
        "      xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0,defined_turn=0.038)\n",
        "    else:\n",
        "      xofymax,intercept,tailhead,slope,diameter,shape,shoulder,ymax=Nyquist_feature_extract(x,y,500,0)\n",
        "\n",
        "    my_dict[r\"pack_xofymax_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=xofymax #x of maximum of Zimg\n",
        "    my_dict[r\"pack_intercept_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=intercept #intercept\n",
        "    my_dict[r\"pack_tailhead_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=tailhead #start of tail\n",
        "    my_dict[r\"pack_slope_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=slope #slope of tail\n",
        "    my_dict[r\"pack_diameter_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=diameter #diameter of semicircle obtained from half max\n",
        "    my_dict[r\"pack_shape_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=shape #shape=representation of shape (0.75max-Rs)/(0.5max-Rs)\n",
        "    my_dict[r\"pack_shoulder_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=shoulder #\n",
        "    my_dict[r\"pack_ymax_P190_0\"+str(i)][\"scan\"+str(int(key[2]))][\"P190_0\"+str(i)+\"_\"+cell[0]]=ymax #maximum of Zimg\n",
        "\n",
        "  #stack features of one pack together to save\n",
        "  Feature=pd.concat([my_dict[\"pack_\"+Feature_name+\"_P190_0\"+str(i)] for Feature_name in [\"xofymax\",\"intercept\",\"diameter\",\"tailhead\",\"slope\",\"shape\",\"shoulder\",\"ymax\"]])\n",
        "  currentDateTime = datetime.now().strftime(\"%m-%d-%Y %H-%M-%S %p\")\n",
        "  Feature.to_csv(\"Generated Features/P190_0\"+str(i)+f\"_features {currentDateTime}.csv\", index = True)"
      ],
      "metadata": {
        "id": "m2MZpKq848u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9c23fe-1051-4a2c-9e2c-6467f4d69d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan08_P190_04_5']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan02_P190_04_1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan02_P190_04_2']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan02_P190_04_3']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan02_P190_04_4']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan02_P190_04_5']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan04_P190_04_1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan04_P190_04_2']\n",
            "['scan04_P190_04_3']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan04_P190_04_4']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan04_P190_04_5']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan06_P190_04_1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan06_P190_04_2']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan06_P190_04_3']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan06_P190_04_4']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan06_P190_04_5']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan08_P190_04_1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan08_P190_04_2']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan08_P190_04_3']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scan08_P190_04_4']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-86a365e9ef65>:54: RankWarning:\n",
            "\n",
            "Polyfit may be poorly conditioned\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCGoxYlZct9G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}